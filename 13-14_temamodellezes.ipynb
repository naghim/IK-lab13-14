{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0433739",
   "metadata": {},
   "source": [
    "# **Témamodellezés (Topic modeling)**\n",
    "\n",
    "A témamodellezés (topic modeling) egy automatizált szövegelemzési módszer, amely képes a dokumentumokban rejlő, tematikusan összefüggő csoportokat, azaz témákat azonosítani és rendszerezni. Az egyik legismertebb és leggyakrabban alkalmazott technika az **LDA (Latent Dirichlet Allocation)**. Az LDA egy valószínűségi modell, amely a dokumentumokban előforduló szavak és témák közötti kapcsolatokat elemzi, és megállapítja, hogy mely szavak tartoznak az egyes témákhoz, valamint milyen mértékben kapcsolódik egy dokumentum egy-egy témához.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c90fa099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07307211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dokumentumok száma: 18846\n",
      "Kategóriák száma: 20\n",
      "\n",
      "Példa dokumentum:\n",
      "\n",
      "\n",
      "I am sure some bashers of Pens fans are pretty confused about the lack\n",
      "of any kind of posts about the recent Pens massacre of the Devils. Actually,\n",
      "I am  bit puzzled too and a bit relieved. However, I am going to put an end\n",
      "to non-PIttsburghers' relief with a bit of praise for the Pens. Man, they\n",
      "are killing those Devils worse than I thought. Jagr just showed you why\n",
      "he is much better than his regular season stats. He is also a lot\n",
      "fo fun to watch in the playoffs. Bowman should let JAgr have a lot of\n",
      "fun in the next couple of games since the Pens are going to beat the pulp out of Jersey anyway. I was very disappointed not to see the Islanders lose the final\n",
      "regular season game.          PENS RULE!!!\n",
      "\n",
      "\n",
      "Kategória: rec.sport.hockey\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Töltsük le a 20 Newsgroups adathalmazt\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "# Az 'data' attribútum tartalmazza a nyers szöveges dokumentumokat\n",
    "# A 'target' attribútum tartalmazza a címkéket (kategóriákat)\n",
    "print(f\"Dokumentumok száma: {len(newsgroups.data)}\")\n",
    "print(f\"Kategóriák száma: {len(newsgroups.target_names)}\")\n",
    "\n",
    "# Példa dokumentum\n",
    "print(\"\\nPélda dokumentum:\")\n",
    "print(newsgroups.data[0])\n",
    "\n",
    "# A megfelelő kategória\n",
    "print(f\"Kategória: {newsgroups.target_names[newsgroups.target[0]]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5174cb",
   "metadata": {},
   "source": [
    "### **Feladat: Adatok kiválasztása és kiírása kategóriák szerint**\n",
    "\n",
    "A 20 Newsgroups adatbázis 20 különböző kategóriába sorolt dokumentumokat tartalmaz. A feladatod, hogy véletlenszerűen válassz ki 5 dokumentumot kategóriánként, és jelenítsd meg őket.\n",
    "\n",
    "#### **Elvárás:**\n",
    "- A betöltött adatokat a `df` DataFrame-ben találod, amely tartalmazza a dokumentumokat (`text` oszlop) és a hozzájuk tartozó kategóriákat (`target_group` oszlop).\n",
    "- A kategóriák nevei a `target_group` oszlop alapján találhatóak.\n",
    "- Kategóriánként válassz ki véletlenszerűen **5 dokumentumot** (ha a kategóriában kevesebb mint 5 dokumentum található, akkor az összes dokumentumot válaszd ki).\n",
    "- Jelenítsd meg a kiválasztott dokumentumokat kategóriánként.\n",
    "- A dokumentumokat és azok kategóriáját **úgy jelenítsd meg, hogy minden kategória alatt a kiválasztott dokumentumok láthatóak legyenek**.\n",
    "\n",
    "#### **Segítség:**\n",
    "- A `sample()` függvényt használhatod a dokumentumok véletlenszerű kiválasztásához kategóriánként.\n",
    "- A kódot úgy írd meg, hogy minden kategória alatt jelenjen meg a kiválasztott 5 dokumentum.\n",
    "- Az egyes kategóriák közötti elválasztáshoz egy `=` karakterekből készült sort is kiírhatsz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a4a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'text': newsgroups.data,  # A dokumentumok szövege\n",
    "    'target_group': [newsgroups.target_names[target] for target in newsgroups.target],  # A célkategóriák\n",
    "    'target_group_encoded': [target for target in newsgroups.target]  # A kategóriák kódolt értékei\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89c9e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "\n",
    "for category in df['target_group'].unique():\n",
    "    #TODO: Megoldás\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bba72e",
   "metadata": {},
   "source": [
    "### **Feladat: Szöveg előfeldolgozása**\n",
    "\n",
    "A feladatod, hogy végezz el egy alapvető előfeldolgozást a 20 Newsgroups adatbázis dokumentumain. Az előfeldolgozás során az alábbi műveleteket kell végrehajtani:\n",
    "\n",
    "#### **Elvárás:**\n",
    "- Az adatokat a `df` DataFrame tartalmazza, amelynek a `text` oszlopában találhatóak a dokumentumok.\n",
    "- Az előfeldolgozás során az alábbi műveleteket hajtsd végre:\n",
    "  - **Kisbetűsítés**: Minden szöveget alakíts át kisbetűsre.\n",
    "  - **Extra szóközök eltávolítása**: A szövegben lévő többszörös szóközöket egyetlen szóközre cseréld.\n",
    "  - **Speciális karakterek eltávolítása**: Távolítsd el a nem betűket és szóközöket (például számokat és írásjeleket).\n",
    "\n",
    "#### **Segítség:**\n",
    "- A fenti műveletekhez használj reguláris kifejezéseket (`re` modul) a Pythonban.\n",
    "- A szöveg előfeldolgozásának eredményét tárold egy új oszlopban, amelyet nevezz el `preprocessed_text`-nek.\n",
    "\n",
    "#### **Példa:**\n",
    "- Eredeti szöveg: `\"Hello! This is an example... text 123.\"`\n",
    "- Előfeldolgozott szöveg: `\"hello this is an example text\"`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddf1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# TODO: Definiálj egy függvényt az alapvető szöveg előfeldolgozáshoz\n",
    "def preprocess(text):\n",
    "    # Alakítsd át kisbetűssé\n",
    "    text = # IDE KELL A KÓD\n",
    "    \n",
    "    # Távolítsd el a fölösleges szóközöket\n",
    "    text = # IDE KELL A KÓD\n",
    "    \n",
    "    # Távolítsd el a speciális karaktereket (minden, ami nem betű vagy szóköz)\n",
    "    text = # IDE KELL A KÓD\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Alkalmazd az előfeldolgozó függvényt a 'text' oszlopra\n",
    "df['preprocessed_text'] = df['text'].apply(preprocess)\n",
    "\n",
    "# Az előfeldolgozott szövegekkel rendelkező DataFrame megjelenítése\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ea00fd",
   "metadata": {},
   "source": [
    "### **Mi az a TF-IDF?**\n",
    "\n",
    "A **TF-IDF** (Term Frequency-Inverse Document Frequency) egy olyan módszer, amely a szövegek jellemzőinek (kifejezéseinek) fontosságát méri egy dokumentumgyűjteményben. Két tényezőt vesz figyelembe:\n",
    "1. **TF (Term Frequency)**: Egy kifejezés előfordulásának gyakorisága egy adott dokumentumban.\n",
    "2. **IDF (Inverse Document Frequency)**: A kifejezés ritkasága a dokumentumgyűjteményben. Minél ritkábban fordul elő egy kifejezés, annál nagyobb súlyt kap.\n",
    "\n",
    "A TF-IDF segítségével azokat a kifejezéseket emeljük ki, amelyek egy adott dokumentumban gyakran előfordulnak, de ritkán a többi dokumentumban, így jelezve, hogy ezek a kifejezések valószínűleg fontosabbak a dokumentumban"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc5ca64",
   "metadata": {},
   "source": [
    "### **Feladat: TF-IDF vektorozás alkalmazása**\n",
    "\n",
    "A célod, hogy alkalmazz egy **TF-IDF** (Term Frequency-Inverse Document Frequency) vektorizálást a szövegekhez, és megvizsgáld az eredményül kapott mátrixot.\n",
    "\n",
    "#### **Elvárás:**\n",
    "1. Alkalmazz egy **TF-IDF vektorozót** a `preprocessed_text` oszlopra, hogy a szövegeket vektorokká alakítsd.\n",
    "2. A `TfidfVectorizer`-t az alábbi paraméterekkel kell használni:\n",
    "   - `stop_words='english'` – az angol nyelvű gyakori szavakat (stop szavakat) távolítsd el.\n",
    "   - `max_features=10000` – maximalizáld a kinyert jellemzők számát 10,000-ra.\n",
    "3. A vektorozás eredményeként egy **TF-IDF mátrixot** kell létrehozni, amit az `X` változóban tárolsz.\n",
    "4. Vizsgáld meg a TF-IDF mátrix formáját és az összes jellemző (kifejezés) nevét.\n",
    "5. A kinyert jellemzők neveit tárold a `feature_names` változóban.\n",
    "\n",
    "#### **Segítség:**\n",
    "- A `TfidfVectorizer` segít a szövegek vektorokká alakításában a TF-IDF súlyozás segítségével.\n",
    "- A `get_feature_names_out()` függvénnyel lekérheted az összes kifejezést, amelyet a vektorozó használt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0457e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer(stop_words='english',max_features=10000)\n",
    "X = vectorizer.fit_transform(df['preprocessed_text'])\n",
    "\n",
    "# Inspect the TF-IDF matrix\n",
    "print(X.shape)  # Number of documents x number of terms\n",
    "print(vectorizer.get_feature_names_out())  # List of terms (features)\n",
    "\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672724b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = None #TODO: Hozd létre a vektorózot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571c273e",
   "metadata": {},
   "source": [
    "### **Mi a célja a feladatnak?**\n",
    "\n",
    "A feladat célja, hogy meghatározd az egyes kategóriák legfontosabb jellemzőit (kifejezéseit) a **TF-IDF** módszer alkalmazásával, majd rendezd őket az átlagos TF-IDF pontszámuk alapján.\n",
    "\n",
    "### **Feladat: Legfontosabb jellemzők meghatározása kategóriánként**\n",
    "\n",
    "#### **Elvárás:**\n",
    "1. **Adatok betöltése**:\n",
    "   - Használj egy **TF-IDF mátrixot** (`X`), amely a szövegeket jellemzővé alakítja.\n",
    "   - Az adatokat tartalmazó DataFrame `df_features` oszlopainak tartalmaznia kell a következőket:\n",
    "     - `feature_names` – a jellemzők nevei (kifejezések).\n",
    "     - `target` – az egyes dokumentumok kategóriái.\n",
    "   \n",
    "2. **Legfontosabb kifejezések kiszámítása**:\n",
    "   - Válassz ki egy **Top N** számú kifejezést (10 kifejezés például) minden kategória számára a **TF-IDF pontszám** alapján. A kifejezéseket az átlagos TF-IDF pontszámuk szerint kell rendezni csökkenő sorrendben.\n",
    "   \n",
    "3. **Kategóriák legfontosabb jellemzőinek tárolása**:\n",
    "   - A kategóriák legfontosabb kifejezéseit tárold egy **szótárban** (`top_features_per_group`), ahol a kulcs a kategória neve, az érték pedig a kifejezések listája.\n",
    "\n",
    "4. **Eredmény megjelenítése**:\n",
    "   - Hozz létre egy új oszlopot a `df_features` DataFrame-ben, amely az egyes kategóriákhoz tartozó **legfontosabb kifejezéseket** mutatja.\n",
    "   - A végső DataFrame-nek az alábbi oszlopokat kell tartalmaznia:\n",
    "     - `category_name` – a kategória neve.\n",
    "     - `top_features` – a kategóriához tartozó legfontosabb kifejezések listája.\n",
    "\n",
    "#### **Segítség:**\n",
    "- A `mean()` függvény segítségével kiszámíthatod az egyes kifejezések átlagos TF-IDF pontszámát minden kategóriánál.\n",
    "- A `sort_values()` függvénnyel rendezheted a kifejezéseket csökkenő sorrendbe.\n",
    "- A `map()` és `apply()` függvények segítségével hozzárendelheted a kategóriák neveit és a legfontosabb kifejezéseket a DataFrame-hez.\n",
    "\n",
    "#### **Eredmény:**\n",
    "A feladat végén egy DataFrame-et kell kapnod, amely tartalmazza az egyes kategóriák legfontosabb kifejezéseit, valamint a hozzájuk tartozó kategóriák neveit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850e3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "df_features['target'] = newsgroups.target  # Célcsoportok (kategóriák) hozzáadása\n",
    "\n",
    "# Definiáljuk, hány legfontosabb kifejezést szeretnénk kategóriánként\n",
    "top_n = 10  \n",
    "\n",
    "# Létrehozunk egy szótárat, hogy tároljuk a legfontosabb N kifejezést minden kategóriához\n",
    "top_features_per_group = {}\n",
    "\n",
    "# Végigmegyünk az összes kategórián\n",
    "for category_idx, category_name in enumerate(newsgroups.target_names):\n",
    "    pass\n",
    "\n",
    "print(df_features[['category_name', 'top_features']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fee3445",
   "metadata": {},
   "source": [
    "### **Mi az az LDA (Latent Dirichlet Allocation)?**\n",
    "\n",
    "Az **LDA (Latent Dirichlet Allocation)** egy gépi tanulási algoritmus, amely segít a dokumentumok témákra bontásában. Az LDA célja, hogy egy nagy szöveges adatbázisból **rejtett témákat találjon**, és hozzárendelje a dokumentumokat ezekhez a témákhoz. \n",
    "\n",
    "#### **Hogyan működik?**\n",
    "- Az LDA úgy képzeli el a dokumentumokat, mint **témák keverékét**.\n",
    "- Minden téma egy adott szavak összességéből áll, és minden dokumentumnak van egy olyan **témakeveréke**, ami meghatározza, hogy melyik témák dominálnak benne.\n",
    "- Az algoritmus megpróbálja **megtalálni a legfontosabb szavakat** minden témához, és ez alapján csoportosítja a dokumentumokat.\n",
    "\n",
    "#### **Miért hasznos?**\n",
    "- Segít **automatikusan kategorizálni** a dokumentumokat a témáik szerint.\n",
    "- Lehetővé teszi a **szövegek elemzését** és a **rejtett minták** felfedezését nagy adathalmazokban."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc08ab8",
   "metadata": {},
   "source": [
    "### **Feladat: Témamodellezés LDA-val**\n",
    "\n",
    "A feladat célja, hogy alkalmazzuk a Latent Dirichlet Allocation (LDA) modellt a dokumentumok témáinak (topics) felfedezésére. Az LDA célja, hogy minden dokumentumból kinyerjenek a hozzájuk tartozó rejtett témákat.\n",
    "\n",
    "#### **Elvárások:**\n",
    "1. Alkalmazz LDA modellt a dokumentumokra, és állítsd be a kívánt számú témát (`n_topics`). Használj 20 témát.\n",
    "2. A LDA alkalmazása után az **`doc_topic_distribution`** változóban tárold a dokumentumokhoz tartozó témák valószínűségeit.\n",
    "3. Az **`lda.components_`** tartalmazza az egyes témákhoz tartozó szóeloszlásokat.\n",
    "4. Minden témához jelenítsd meg a legfontosabb 10 szót, amelyek a témához tartoznak. A legfontosabb szavak kiválasztásához használd a `topic.argsort()` funkciót.\n",
    "5. A legfontosabb szavak megjelenítése során a következő információkat tartsd szem előtt:\n",
    "   - Minden téma esetében írd ki a legnagyobb súllyal rendelkező szavakat.\n",
    "   - A szavakat a **TF-IDF**-val rendelkező szavak sorrendjében jelenítsd meg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2059c653",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "n_topics = 20\n",
    "\n",
    "#TODO: Hozd létre az LDA modellt\n",
    "\n",
    "doc_topic_distribution = None "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3c835c",
   "metadata": {},
   "source": [
    "### **Feladat: A témák legfontosabb szavainak vizualizálása**\n",
    "\n",
    "A **Latent Dirichlet Allocation (LDA)** segítségével témákat alkottunk a dokumentumokból. Az a feladat, hogy vizualizáljuk a legfontosabb szavakat minden egyes témához. \n",
    "\n",
    "#### **Elvárások:**\n",
    "1. A **TF-IDF** modellezés alapján határozd meg a legfontosabb szavakat minden témához.\n",
    "2. A **matplotlib** könyvtár segítségével készíts egy oszlopdiagramot, amely megjeleníti az egyes témák legfontosabb szavait és azok fontosságát (TF-IDF értékét).\n",
    "3. Az oszlopdiagramon a legfontosabb szavak legyenek a **y-tengelyen**, és a szavak fontossága (TF-IDF érték) jelenjen meg az **x-tengelyen**.\n",
    "4. Az **y-tengely** legyen **fordított**, hogy a legfontosabb szó legyen felül.\n",
    "5. A grafikon címében jelenjen meg a téma száma, például: \"A 10 legfontosabb szó a 1. témában\".\n",
    "6. Készíts diagramot minden témához, de csak az elsőt jelenítsd meg.\n",
    "\n",
    "#### **A feladathoz szükséges változók:**\n",
    "- **`lda.components_`**: Az LDA modell komponensei, melyek tartalmazzák a szavak és témák közötti kapcsolatokat.\n",
    "- **`vectorizer.get_feature_names_out()`**: A szavak listája, amelyet a TF-IDF modellezés hozott létre.\n",
    "- **`n_top_words`**: A legfontosabb szavak száma, amelyeket meg szeretnél jeleníteni a diagramon.\n",
    "\n",
    "#### **Követelmények:**\n",
    "- Használj **`matplotlib`** könyvtárat a grafikon elkészítéséhez.\n",
    "- Az oszlopdiagram a témák legfontosabb szavait kell, hogy megjelenítse a TF-IDF értékeikkel együtt.\n",
    "- Gondoskodj róla, hogy az oszlopok a legfontosabb szavak szerint legyenek rendezve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f04f80e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# A téma legfontosabb szavainak száma\n",
    "n_top_words = 10\n",
    "\n",
    "# A jellemzők nevei (szavak) lekérése\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Készítsünk oszlopdiagramot a legfontosabb szavakhoz minden témához\n",
    "for topic_idx, topic in enumerate(lda.components_):\n",
    "    # A legfontosabb szavak indexeinek lekérése (rendezett sorrendben)\n",
    "    top_words_idx = topic.argsort()[-n_top_words:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_words_idx]\n",
    "    top_word_scores = topic[top_words_idx]\n",
    "\n",
    "    #TODO: Készítsd el a diagramot\n",
    "    \n",
    "    break\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c795e34",
   "metadata": {},
   "source": [
    "### **Feladat: Kategóriák arányának vizualizálása**\n",
    "\n",
    "A feladat célja, hogy vizualizáljuk a dokumentumok arányát a különböző kategóriák (target_group) között a **df** adatkeretben.\n",
    "\n",
    "#### **Elvárások:**\n",
    "1. Számold ki a dokumentumok arányát minden egyes kategóriában (target_group) a `value_counts(normalize=True)` segítségével.\n",
    "2. Készíts egy oszlopdiagramot, amely a kategóriák (target_group) arányát mutatja a dokumentumok között.\n",
    "3. A diagram **x-tengelyén** a kategóriák nevei szerepeljenek, míg az **y-tengelyen** azok az arányok, amelyeket a kategóriák dokumentumainak száma alapján számoltál ki.\n",
    "4. Az oszlopdiagramon a kategóriák neveit **forgasd el 90 fokkal**, hogy jól olvashatóak legyenek.\n",
    "5. A diagram címeként tüntesd fel: \"Kategóriák arányai a dokumentumok között\".\n",
    "\n",
    "#### **A feladathoz szükséges változók:**\n",
    "- **`df['target_group']`**: A dokumentumok kategóriáját tartalmazó oszlop.\n",
    "- **`value_counts(normalize=True)`**: A dokumentumok arányának kiszámítása kategóriánként.\n",
    "\n",
    "#### **Követelmények:**\n",
    "- Használj **`matplotlib`** könyvtárat a diagram elkészítéséhez.\n",
    "- Az y-tengelyen a dokumentumok kategóriák szerinti arányát kell megjeleníteni, százalékban.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834320fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Számold ki a dokumentumok arányát kategóriánként (target_group)\n",
    "target_group_proportions = df['target_group'].value_counts(normalize=True)\n",
    "\n",
    "#TODO: Ábrázold a kategóriák arányait"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b173fd2",
   "metadata": {},
   "source": [
    "### **Feladat: Téma arányok vizualizálása**\n",
    "\n",
    "Miután alkalmaztad a Latent Dirichlet Allocation (LDA) modellt, a feladat célja, hogy megjelenítsd a témák eloszlását a dokumentumok között.\n",
    "\n",
    "#### **Elvárások:**\n",
    "1. Az **`doc_topic_distribution`** változó tartalmazza a dokumentumokhoz rendelt témák eloszlását.\n",
    "2. Számítsd ki a témák átlagos arányait a **`topic_proportions`** változóban.\n",
    "3. Ábrázold a témák arányát egy oszlopdiagramon. Minden téma arányát jelenítsd meg a diagramon.\n",
    "4. Az X-tengelyen a témák számát jelenítsd meg (pl. T1, T2, ..., T20).\n",
    "5. Az Y-tengelyen a témák dokumentumokban való arányát jelenítsd meg (százalékban).\n",
    "6. A grafikon címét és az Y-tengely címét magyarul add meg:\n",
    "   - Cím: \"Téma arányok a dokumentumok között\"\n",
    "   - Y-tengely: \"Dokumentumok aránya\"\n",
    "\n",
    "#### **A feladathoz szükséges változók:**\n",
    "- **`doc_topic_distribution`**: A dokumentumokhoz tartozó témák eloszlása.\n",
    "- **`topic_proportions`**: A témák átlagos aránya, amit kiszámítasz a dokumentumok eloszlása alapján.\n",
    "- **`n_topics`**: A témák száma.\n",
    "\n",
    "#### **Követelmények:**\n",
    "- Használj **`matplotlib`** könyvtárat az ábra elkészítéséhez.\n",
    "- A diagram oszlopai a témák arányait mutassák, és a címek és tengelyek legyenek megfelelőek.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f1d6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_proportions = doc_topic_distribution.mean(axis=0)\n",
    "\n",
    "# TODO: Téma arányok ábrázolása"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
